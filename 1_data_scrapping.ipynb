{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dfad5d-42bf-4c45-a7fa-d44bd10b356b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8821383d-1091-4843-b2fb-c04fe11845cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the beautifulsoup \n",
    "# and request libraries of python.\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd46d7d-f511-40ea-b335-4d00c948cdb0",
   "metadata": {},
   "source": [
    "# Scrapping Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb198e5a-5b45-41fa-9eb4-b19d42ea79b6",
   "metadata": {},
   "source": [
    "It will scrap a search result from https://www.kompas.com/ for 50 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3957c750-03fe-44b9-b10b-a83b08b614d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date collection: 2022-12-03 16:59:10.992924 \n",
      "\n",
      "scrapping for page 1, request status: <Response [200]> ...\n",
      "scrapping for page 2, request status: <Response [200]> ...\n",
      "scrapping for page 3, request status: <Response [200]> ...\n",
      "scrapping for page 4, request status: <Response [200]> ...\n",
      "scrapping for page 5, request status: <Response [200]> ...\n",
      "scrapping for page 6, request status: <Response [200]> ...\n",
      "scrapping for page 7, request status: <Response [200]> ...\n",
      "scrapping for page 8, request status: <Response [200]> ...\n",
      "scrapping for page 9, request status: <Response [200]> ...\n",
      "scrapping for page 10, request status: <Response [200]> ...\n",
      "scrapping for page 11, request status: <Response [200]> ...\n",
      "scrapping for page 12, request status: <Response [200]> ...\n",
      "scrapping for page 13, request status: <Response [200]> ...\n",
      "scrapping for page 14, request status: <Response [200]> ...\n",
      "scrapping for page 15, request status: <Response [200]> ...\n",
      "scrapping for page 16, request status: <Response [200]> ...\n",
      "scrapping for page 17, request status: <Response [200]> ...\n",
      "scrapping for page 18, request status: <Response [200]> ...\n",
      "scrapping for page 19, request status: <Response [200]> ...\n",
      "scrapping for page 20, request status: <Response [200]> ...\n",
      "scrapping for page 21, request status: <Response [200]> ...\n",
      "scrapping for page 22, request status: <Response [200]> ...\n",
      "scrapping for page 23, request status: <Response [200]> ...\n",
      "scrapping for page 24, request status: <Response [200]> ...\n",
      "scrapping for page 25, request status: <Response [200]> ...\n",
      "scrapping for page 26, request status: <Response [200]> ...\n",
      "scrapping for page 27, request status: <Response [200]> ...\n",
      "scrapping for page 28, request status: <Response [200]> ...\n",
      "scrapping for page 29, request status: <Response [200]> ...\n",
      "scrapping for page 30, request status: <Response [200]> ...\n",
      "scrapping for page 31, request status: <Response [200]> ...\n",
      "scrapping for page 32, request status: <Response [200]> ...\n",
      "scrapping for page 33, request status: <Response [200]> ...\n",
      "scrapping for page 34, request status: <Response [200]> ...\n",
      "scrapping for page 35, request status: <Response [200]> ...\n",
      "scrapping for page 36, request status: <Response [200]> ...\n",
      "scrapping for page 37, request status: <Response [200]> ...\n",
      "scrapping for page 38, request status: <Response [200]> ...\n",
      "scrapping for page 39, request status: <Response [200]> ...\n",
      "scrapping for page 40, request status: <Response [200]> ...\n",
      "scrapping for page 41, request status: <Response [200]> ...\n",
      "scrapping for page 42, request status: <Response [200]> ...\n",
      "scrapping for page 43, request status: <Response [200]> ...\n",
      "scrapping for page 44, request status: <Response [200]> ...\n",
      "scrapping for page 45, request status: <Response [200]> ...\n",
      "scrapping for page 46, request status: <Response [200]> ...\n",
      "scrapping for page 47, request status: <Response [200]> ...\n",
      "scrapping for page 48, request status: <Response [200]> ...\n",
      "scrapping for page 49, request status: <Response [200]> ...\n",
      "scrapping for page 50, request status: <Response [200]> ...\n",
      "\n",
      "execution time completed: 0:16:05.406605\n"
     ]
    }
   ],
   "source": [
    "# define content_id\n",
    "pages = 50\n",
    "n_pages = np.arange(1, pages+1, 1)\n",
    "main_topic = 'edukasi'\n",
    "\n",
    "article_link = []\n",
    "article_title = []\n",
    "article_date = []\n",
    "article_content = []\n",
    "\n",
    "# get start time\n",
    "start_time = datetime.now()\n",
    "print('date collection:', start_time, '\\n')\n",
    "\n",
    "for i, page in enumerate(n_pages):\n",
    "    url = f'https://indeks.kompas.com/?site={main_topic}&page={page}'\n",
    "\n",
    "    # Fetch the URL data\n",
    "    request_page_result=requests.get( url )    \n",
    "    print(f'scrapping for page {page}, request status: {request_page_result} ...')\n",
    "\n",
    "    # Creating soup from the fetched request\n",
    "    page_soup = bs4.BeautifulSoup(request_page_result.text,\n",
    "                             \"html.parser\")\n",
    "    article_list = page_soup.find_all('div', class_='article__list__title')\n",
    "    \n",
    "    # get article information\n",
    "    new_article_link = [x.find('a').get('href') for x in article_list]\n",
    "    new_article_title = [x.find('a').text for x in article_list]\n",
    "    \n",
    "    # looping through article\n",
    "    # to get article fontent\n",
    "    for link_ in new_article_link:\n",
    "        request_content=requests.get(link_)\n",
    "        # Creating soup from the fetched request\n",
    "        soup_content = bs4.BeautifulSoup(request_content.text,\n",
    "                                 \"html.parser\")\n",
    "        \n",
    "        # get publish date\n",
    "        script_tag = soup_content.find('script', string=True)\n",
    "        date_publish = re.search(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})', script_tag.text)[0]\n",
    "        \n",
    "        # looping through meta tags\n",
    "        for i, data_link_ in enumerate(soup_content.find_all('meta')):\n",
    "            try:\n",
    "                data_link_.get('name')\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                meta_type = data_link_.get('name')\n",
    "                content_data = data_link_.get('content')\n",
    "                \n",
    "                # append data article\n",
    "                if meta_type =='keyword_brand_safety':\n",
    "                    article_content.extend([content_data])\n",
    "                    article_date.extend([date_publish])\n",
    "    \n",
    "    # append article general informations\n",
    "    article_link.extend(new_article_link)\n",
    "    article_title.extend(new_article_title)\n",
    "    \n",
    "    \n",
    "    # pause search for evry iteration with random number\n",
    "    # the more number the more delay\n",
    "    # it is usefull to avoid security issue\n",
    "    sleep(randint(2,10))\n",
    "    \n",
    "# get finish time\n",
    "finish_time = datetime.now()\n",
    "print('\\nexecution time completed:', finish_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652940a-c818-4963-a819-e092db0fb727",
   "metadata": {},
   "source": [
    "If all responses code are 200, the get request is complete for all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a7f6c8-e84a-40db-9fa2-426bbf59ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_date</th>\n",
       "      <th>article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://edukasi.kompas.com/read/2022/12/03/160...</td>\n",
       "      <td>6 Alasan Pentingnya Belajar Coding Dimulai dar...</td>\n",
       "      <td>2022-12-03 16:07:00</td>\n",
       "      <td>\\nKOMPAS.com - Apabila kamu termasuk siswa yan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/12/03/145...</td>\n",
       "      <td>Lowongan Kerja Kalbe Farma bagi Lulusan Minima...</td>\n",
       "      <td>2022-12-03 14:59:00</td>\n",
       "      <td>\\nKOMPAS.com - PT Kalbe Farma Tbk membuka lowo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/12/03/142...</td>\n",
       "      <td>BUMN Semen Indonesia Buka 8 Lowongan Kerja, Lu...</td>\n",
       "      <td>2022-12-03 14:27:00</td>\n",
       "      <td>\\nKOMPAS.com - Badan Usaha Milik Negara (BUMN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://edukasi.kompas.com/read/2022/12/03/141...</td>\n",
       "      <td>Buah dan Sayur untuk Kesehatan Mata</td>\n",
       "      <td>2022-12-03 14:17:00</td>\n",
       "      <td>\\nKOMPAS.com - Buah dan sayur mengandung banya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/12/03/134...</td>\n",
       "      <td>Contoh Soal Literasi Bahasa Indonesia SNBT 202...</td>\n",
       "      <td>2022-12-03 13:47:00</td>\n",
       "      <td>\\nKOMPAS.com - Jadwal pelaksanaan Ujian Tulis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/11/08/211...</td>\n",
       "      <td>Ditjen Kebudayaan Kenalkan Kearifan Lokal kepa...</td>\n",
       "      <td>2022-11-08 21:10:30</td>\n",
       "      <td>\\nKOMPAS.com - Di tengah perhelatan G20 di Bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/11/08/203...</td>\n",
       "      <td>BPIP dan UNJ Gelar Bedah Musik Kebangsaan untu...</td>\n",
       "      <td>2022-11-08 20:36:41</td>\n",
       "      <td>\\nKOMPAS.com -&amp;amp;nbsp;Badan Pembinaan Ideolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>https://edukasi.kompas.com/read/2022/11/08/192...</td>\n",
       "      <td>3 Sekolah Terbaik di Jawa Timur Beserta Profil...</td>\n",
       "      <td>2022-11-08 19:28:32</td>\n",
       "      <td>\\nKOMPAS.com &amp;amp;ndash; Lembaga Tes Masuk Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>https://edukasi.kompas.com/read/2022/11/08/191...</td>\n",
       "      <td>10 Cara Mengatasi Stres pada Mahasiswa</td>\n",
       "      <td>2022-11-08 19:17:00</td>\n",
       "      <td>\\nKOMPAS.com - Saat menjadi mahasiswa tentunya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>https://www.kompas.com/edu/read/2022/11/08/190...</td>\n",
       "      <td>Lulusan Unpad, Ridwan Kamil Beri Pesan Ini</td>\n",
       "      <td>2022-11-08 19:07:21</td>\n",
       "      <td>\\nKOMPAS.com - Gubernur Jawa Barat (Jabar) Rid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          article_link  \\\n",
       "0    https://edukasi.kompas.com/read/2022/12/03/160...   \n",
       "1    https://www.kompas.com/edu/read/2022/12/03/145...   \n",
       "2    https://www.kompas.com/edu/read/2022/12/03/142...   \n",
       "3    https://edukasi.kompas.com/read/2022/12/03/141...   \n",
       "4    https://www.kompas.com/edu/read/2022/12/03/134...   \n",
       "..                                                 ...   \n",
       "745  https://www.kompas.com/edu/read/2022/11/08/211...   \n",
       "746  https://www.kompas.com/edu/read/2022/11/08/203...   \n",
       "747  https://edukasi.kompas.com/read/2022/11/08/192...   \n",
       "748  https://edukasi.kompas.com/read/2022/11/08/191...   \n",
       "749  https://www.kompas.com/edu/read/2022/11/08/190...   \n",
       "\n",
       "                                         article_title         article_date  \\\n",
       "0    6 Alasan Pentingnya Belajar Coding Dimulai dar...  2022-12-03 16:07:00   \n",
       "1    Lowongan Kerja Kalbe Farma bagi Lulusan Minima...  2022-12-03 14:59:00   \n",
       "2    BUMN Semen Indonesia Buka 8 Lowongan Kerja, Lu...  2022-12-03 14:27:00   \n",
       "3                  Buah dan Sayur untuk Kesehatan Mata  2022-12-03 14:17:00   \n",
       "4    Contoh Soal Literasi Bahasa Indonesia SNBT 202...  2022-12-03 13:47:00   \n",
       "..                                                 ...                  ...   \n",
       "745  Ditjen Kebudayaan Kenalkan Kearifan Lokal kepa...  2022-11-08 21:10:30   \n",
       "746  BPIP dan UNJ Gelar Bedah Musik Kebangsaan untu...  2022-11-08 20:36:41   \n",
       "747  3 Sekolah Terbaik di Jawa Timur Beserta Profil...  2022-11-08 19:28:32   \n",
       "748             10 Cara Mengatasi Stres pada Mahasiswa  2022-11-08 19:17:00   \n",
       "749         Lulusan Unpad, Ridwan Kamil Beri Pesan Ini  2022-11-08 19:07:21   \n",
       "\n",
       "                                       article_content  \n",
       "0    \\nKOMPAS.com - Apabila kamu termasuk siswa yan...  \n",
       "1    \\nKOMPAS.com - PT Kalbe Farma Tbk membuka lowo...  \n",
       "2    \\nKOMPAS.com - Badan Usaha Milik Negara (BUMN)...  \n",
       "3    \\nKOMPAS.com - Buah dan sayur mengandung banya...  \n",
       "4    \\nKOMPAS.com - Jadwal pelaksanaan Ujian Tulis ...  \n",
       "..                                                 ...  \n",
       "745  \\nKOMPAS.com - Di tengah perhelatan G20 di Bal...  \n",
       "746  \\nKOMPAS.com -&amp;nbsp;Badan Pembinaan Ideolo...  \n",
       "747  \\nKOMPAS.com &amp;ndash; Lembaga Tes Masuk Per...  \n",
       "748  \\nKOMPAS.com - Saat menjadi mahasiswa tentunya...  \n",
       "749  \\nKOMPAS.com - Gubernur Jawa Barat (Jabar) Rid...  \n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df_result = pd.DataFrame({\n",
    "    'article_link':article_link,\n",
    "    'article_title':article_title,\n",
    "    'article_date':article_date,\n",
    "    \"article_content\":article_content})\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafe2db-c445-4d0c-8bf6-c5e5d5ac28f2",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab55eedd-9827-45d2-b147-60be64628a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "file_path = os.path.join('dataset', \"scrapping_result.csv\")\n",
    "df_result.to_csv(file_path, sep=',', index=False, quoting=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7a8bbf8280d739911ee0fb92c2a18e877feb5454e3bd0217f9b485bdc87c128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
